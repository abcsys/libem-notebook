{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze provided results from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "folder_prefix = '../match/'\n",
    "\n",
    "dataset_names = {\n",
    "    'abt-buy-sampled-gs_domain-complex-force': 'abt-buy-gs',\n",
    "    'walmart-amazon-sampled-gs_domain-complex-force': 'walmart-amazon-gs',\n",
    "    'amazon-google-sampled-gs_domain-complex-force': 'amazon-google-gs',\n",
    "    'dblp-scholar-sampled-gs_domain-complex-force': 'dblp-scholar-gs',\n",
    "    # 'wdcproducts-80cc-seen-sampled-250-gs-2_domain-complex-force': 'wdcproducts-80cc-seen-gs',\n",
    "    'dblp-acm-sampled-gs_domain-complex-force': 'dblp-acm-gs'\n",
    "}\n",
    "\n",
    "def format_output_prod(line):\n",
    "    split = line.split('\\n')\n",
    "    assert(len(split) == 2)\n",
    "    return {\n",
    "        \"Product 1\": split[0][12:-1],\n",
    "        \"Product 2\": split[1][12:-1]\n",
    "    }\n",
    "\n",
    "def format_output_pub(line):\n",
    "    split = line.split('\\n')\n",
    "    assert(len(split) == 2)\n",
    "    return {\n",
    "        \"Publication 1\": split[0][16:-1],\n",
    "        \"Publication 2\": split[1][16:-1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_all, true_neg_all, false_pos_all, false_neg_all = {}, {}, {}, {}\n",
    "accuracy, f1, precision, recall = {}, {}, {}, {}\n",
    "\n",
    "for d in dataset_names.keys():\n",
    "\n",
    "    # read in data\n",
    "    with open(f'../libem-sample-data/{dataset_names[d][:-3]}/test.ndjson', 'r') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "    with open(f'{folder_prefix}LLMForEM/prompt-answer-combined/prompts_and_answers/{d}_default_gpt-4-0613_run-1.jsonl', 'r') as f:\n",
    "        results = [json.loads(line) for line in f]\n",
    "\n",
    "    # process results\n",
    "    true_pos, true_neg, false_pos, false_neg, bad_format = [], [], [], [], []\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        # make sure prompt matches and format output\n",
    "        data = results[i]['prompt']\n",
    "        \n",
    "        if results[i]['answer'] == 'Yes':\n",
    "            if (dataset[i]['label'] == 1):\n",
    "                true_pos.append(data)\n",
    "                correct += 1\n",
    "            else:\n",
    "                false_pos.append(data)\n",
    "        elif results[i]['answer'] == 'No':\n",
    "            if (dataset[i]['label'] == 0):\n",
    "                true_neg.append(data)\n",
    "                correct += 1\n",
    "            else:\n",
    "                false_neg.append(data)\n",
    "        else:\n",
    "            bad_format.append(results[i])\n",
    "    \n",
    "    assert(len(bad_format) == 0)\n",
    "    # print(len(results))\n",
    "    name = dataset_names[d][:-3]\n",
    "    \n",
    "    true_pos_all[name], true_neg_all[name], false_pos_all[name], false_neg_all[name] = true_pos, true_neg, false_pos, false_neg\n",
    "    accuracy[name], precision[name], recall[name] = correct/len(data), len(true_pos) / (len(true_pos) + len(false_pos)), len(true_pos) / (len(true_pos) + len(false_neg))\n",
    "    f1[name] = 2 * len(true_pos) / (2 * len(true_pos) + len(false_pos) + len(false_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./paper-results/true_pos.json', 'w') as f:\n",
    "        json.dump(true_pos_all, f, indent=4)\n",
    "with open(f'./paper-results/true_neg.json', 'w') as f:\n",
    "        json.dump(true_neg_all, f, indent=4)\n",
    "with open(f'./paper-results/false_pos.json', 'w') as f:\n",
    "        json.dump(false_pos_all, f, indent=4)\n",
    "with open(f'./paper-results/false_neg.json', 'w') as f:\n",
    "        json.dump(false_neg_all, f, indent=4)\n",
    "with open(f'./paper-results/f1.json', 'w') as f:\n",
    "        json.dump(f1, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abt-buy</th>\n",
       "      <td>95.1</td>\n",
       "      <td>95.1</td>\n",
       "      <td>95.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walmart-amazon</th>\n",
       "      <td>84.3</td>\n",
       "      <td>94.3</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon-google</th>\n",
       "      <td>63.8</td>\n",
       "      <td>92.7</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dblp-scholar</th>\n",
       "      <td>89.7</td>\n",
       "      <td>87.2</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dblp-acm</th>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Precision  Recall    F1\n",
       "abt-buy              95.1    95.1  95.1\n",
       "walmart-amazon       84.3    94.3  89.0\n",
       "amazon-google        63.8    92.7  75.6\n",
       "dblp-scholar         89.7    87.2  88.4\n",
       "dblp-acm             94.0   100.0  96.9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Precision'] = pd.Series(precision)\n",
    "df['Recall'] = pd.Series(recall)\n",
    "df['F1'] = pd.Series(f1)\n",
    "df['Precision'] *= 100\n",
    "df['Recall'] *= 100\n",
    "df['F1'] *= 100\n",
    "df.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze reproduced paper (no schema) results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "folder = 'no-schema-gpt4-turbo'\n",
    "\n",
    "dataset_names = {\n",
    "    'abt-buy-sampled-gs_domain-complex-force': 'abt-buy-gs',\n",
    "    'walmart-amazon-sampled-gs_domain-complex-force': 'walmart-amazon-gs',\n",
    "    'amazon-google-sampled-gs_domain-complex-force': 'amazon-google-gs',\n",
    "    'dblp-scholar-sampled-gs_domain-complex-force': 'dblp-scholar-gs',\n",
    "    # 'wdcproducts-80cc-seen-sampled-250-gs-2_domain-complex-force': 'wdcproducts-80cc-seen-gs',\n",
    "    'dblp-acm-sampled-gs_domain-complex-force': 'dblp-acm-gs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output_prod(line):\n",
    "    split = line.split('\\n')\n",
    "    assert(len(split) == 2)\n",
    "    return {\n",
    "        \"Product 1\": split[0][12:-1],\n",
    "        \"Product 2\": split[1][12:-1]\n",
    "    }\n",
    "\n",
    "def format_output_pub(line):\n",
    "    split = line.split('\\n')\n",
    "    assert(len(split) == 2)\n",
    "    return {\n",
    "        \"Publication 1\": split[0][16:-1],\n",
    "        \"Publication 2\": split[1][16:-1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_all, true_neg_all, false_pos_all, false_neg_all = {}, {}, {}, {}\n",
    "accuracy, f1, precision, recall = {}, {}, {}, {}\n",
    "\n",
    "for d in dataset_names.keys():\n",
    "    \n",
    "    # read in results\n",
    "    if d != 'dblp-acm-sampled-gs_domain-complex-force':\n",
    "        with open(f'./LLMForEM/tasks/{d}.json', 'r') as f:\n",
    "            dataset = json.load(f)['examples']\n",
    "    with open(f\"./{folder}/{d}_results.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "        \n",
    "    # process results\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "    correct, pos, neg = 0, 0, 0\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if d != 'dblp-acm-sampled-gs_domain-complex-force':\n",
    "            # make sure prompt matches and format output\n",
    "            if (d == 'dblp-scholar-sampled-gs_domain-complex-force'):\n",
    "                assert(results[i]['prompt'][120:] == dataset[i]['input'])\n",
    "                data = format_output_pub(dataset[i]['input'])\n",
    "            else:\n",
    "                assert(results[i]['prompt'][124:] == dataset[i]['input'])\n",
    "                data = format_output_prod(dataset[i]['input'])\n",
    "            \n",
    "            if (results[i]['answer'][0:3] == 'Yes'):\n",
    "                if (dataset[i]['target_scores']['Yes'] == 1):\n",
    "                    true_pos.append(data)\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    false_pos.append(data)\n",
    "            else:\n",
    "                if (dataset[i]['target_scores']['No'] == 1):\n",
    "                    true_neg.append(data)\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    false_neg.append(data)\n",
    "        else:\n",
    "            if results[i]['Match'][0:3] == 'yes':\n",
    "                if results[i]['Label'] == 1:\n",
    "                    true_pos.append(data)\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    false_pos.append(data)\n",
    "            else:\n",
    "                if results[i]['Label'] == 0:\n",
    "                    true_neg.append(data)\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    false_neg.append(data)\n",
    "    \n",
    "    name = dataset_names[d]\n",
    "    \n",
    "    true_pos_all[name], true_neg_all[name], false_pos_all[name], false_neg_all[name] = true_pos, true_neg, false_pos, false_neg\n",
    "    accuracy[name], precision[name], recall[name] = correct/len(data), len(true_pos) / (len(true_pos) + len(false_pos)), len(true_pos) / (len(true_pos) + len(false_neg))\n",
    "    f1[name] = 2 * len(true_pos) / (2 * len(true_pos) + len(false_pos) + len(false_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./{folder}/true_pos.json', 'w') as f:\n",
    "        json.dump(true_pos_all, f, indent=4)\n",
    "with open(f'./{folder}/true_neg.json', 'w') as f:\n",
    "        json.dump(true_neg_all, f, indent=4)\n",
    "with open(f'./{folder}/false_pos.json', 'w') as f:\n",
    "        json.dump(false_pos_all, f, indent=4)\n",
    "with open(f'./{folder}/false_neg.json', 'w') as f:\n",
    "        json.dump(false_neg_all, f, indent=4)\n",
    "# with open(f'./{folder}/accuracy.json', 'w') as f:\n",
    "#         json.dump(accuracy, f, indent=4)\n",
    "with open(f'./{folder}/f1.json', 'w') as f:\n",
    "        json.dump(f1, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Precision'] = pd.Series(precision)\n",
    "df['Recall'] = pd.Series(recall)\n",
    "df['F1'] = pd.Series(f1)\n",
    "df['Precision'] *= 100\n",
    "df['Recall'] *= 100\n",
    "df['F1'] *= 100\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(df['F1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze with schema results, sampled (test) set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "folder = '../match/with-schema-gpt4-turbo'\n",
    "dataset_names = {\n",
    "    'abt-buy-sampled-gs_domain-complex-force': 'abt-buy-gs',\n",
    "    'walmart-amazon-sampled-gs_domain-complex-force': 'walmart-amazon-gs',\n",
    "    'amazon-google-sampled-gs_domain-complex-force': 'amazon-google-gs',\n",
    "    'dblp-scholar-sampled-gs_domain-complex-force': 'dblp-scholar-gs',\n",
    "    # 'wdcproducts-80cc-seen-sampled-250-gs-2_domain-complex-force': 'wdcproducts-80cc-seen-gs',\n",
    "    'dblp-acm-sampled-gs_domain-complex-force': 'dblp-acm-gs'\n",
    "}\n",
    "\n",
    "true_pos_all, true_neg_all, false_pos_all, false_neg_all = {}, {}, {}, {}\n",
    "accuracy, precision, recall, f1 = {}, {}, {}, {}\n",
    "\n",
    "for d_k in dataset_names.keys():\n",
    "    name = dataset_names[d_k]\n",
    "    \n",
    "    with open(f'../libem-sample-data/{name[:-3]}/test.ndjson', 'r') as fi:\n",
    "        in_set = [json.loads(line)['pair_id'] for line in fi]\n",
    "    \n",
    "    # read in results\n",
    "    with open(f\"{folder}/{name}_results.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "        # process results\n",
    "        true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "        correct, pos, neg = 0, 0, 0\n",
    "    \n",
    "        for d in data:\n",
    "            # find if in sampled data\n",
    "            prod1 = d['product 1']\n",
    "            prod2 = d['product 2']\n",
    "            \n",
    "            id_pair = prod1[7: prod1.find('\",\"')] + '#' + prod2[6: prod2.find('\",\"')]\n",
    "            if not id_pair in in_set:\n",
    "                continue\n",
    "            \n",
    "            output = {'product 1': d['product 1'], 'product 2': d['product 2']}\n",
    "            if d['response'][0:3] == 'Yes':\n",
    "                if d['label'] == '1':\n",
    "                    true_pos.append(output)\n",
    "                    correct += 1\n",
    "                    pos += 1\n",
    "                else:\n",
    "                    false_pos.append(output)\n",
    "                    neg += 1\n",
    "            else:\n",
    "                if d['label'] == '0':\n",
    "                    true_neg.append(output)\n",
    "                    correct += 1\n",
    "                    neg += 1\n",
    "                else:\n",
    "                    false_neg.append(output)\n",
    "                    pos += 1\n",
    "        \n",
    "        # make sure filtered set has same length as test set\n",
    "        assert(len(in_set) == len(true_pos) + len(true_neg) + len(false_pos) + len(false_neg))\n",
    "        \n",
    "        true_pos_all[name], true_neg_all[name], false_pos_all[name], false_neg_all[name] = true_pos, true_neg, false_pos, false_neg\n",
    "        accuracy[name], precision[name], recall[name] = correct/(pos + neg), len(true_pos) / (len(true_pos) + len(false_pos)), len(true_pos) / (len(true_pos) + len(false_neg))\n",
    "        f1[name] =  2 * len(true_pos) / (2 * len(true_pos) + len(false_pos) + len(false_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./{folder}/true_pos.json', 'w') as f:\n",
    "        json.dump(true_pos_all, f, indent=4)\n",
    "with open(f'./{folder}/true_neg.json', 'w') as f:\n",
    "        json.dump(true_neg_all, f, indent=4)\n",
    "with open(f'./{folder}/false_pos.json', 'w') as f:\n",
    "        json.dump(false_pos_all, f, indent=4)\n",
    "with open(f'./{folder}/false_neg.json', 'w') as f:\n",
    "        json.dump(false_neg_all, f, indent=4)\n",
    "# with open(f'./{folder}/accuracy.json', 'w') as f:\n",
    "#         json.dump(accuracy, f, indent=4)\n",
    "with open(f'./{folder}/f1.json', 'w') as f:\n",
    "        json.dump(f1, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abt-buy-gs</th>\n",
       "      <td>96.6</td>\n",
       "      <td>96.1</td>\n",
       "      <td>96.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walmart-amazon-gs</th>\n",
       "      <td>78.7</td>\n",
       "      <td>95.9</td>\n",
       "      <td>86.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon-google-gs</th>\n",
       "      <td>71.1</td>\n",
       "      <td>98.7</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dblp-scholar-gs</th>\n",
       "      <td>90.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dblp-acm-gs</th>\n",
       "      <td>96.5</td>\n",
       "      <td>99.6</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Precision  Recall    F1\n",
       "abt-buy-gs              96.6    96.1  96.4\n",
       "walmart-amazon-gs       78.7    95.9  86.4\n",
       "amazon-google-gs        71.1    98.7  82.6\n",
       "dblp-scholar-gs         90.6    96.0  93.2\n",
       "dblp-acm-gs             96.5    99.6  98.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Precision'] = pd.Series(precision)\n",
    "df['Recall'] = pd.Series(recall)\n",
    "df['F1'] = pd.Series(f1)\n",
    "df['Precision'] *= 100\n",
    "df['Recall'] *= 100\n",
    "df['F1'] *= 100\n",
    "df.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze libem run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# dataset name: file location\n",
    "files = {\n",
    "    # 'Without Learning': '../libem/benchmark/results/???.json',\n",
    "    'With Learning': '../libem/benchmark/results/???.json',\n",
    "    }\n",
    "\n",
    "true_pos_all, true_neg_all, false_pos_all, false_neg_all = {}, {}, {}, {}\n",
    "accuracy, precision, recall, f1 = {}, {}, {}, {}\n",
    "\n",
    "for name, file in files.items():\n",
    "    \n",
    "    # read in results\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "        # process results\n",
    "        true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "        correct, pos, neg = 0, 0, 0\n",
    "\n",
    "        for d in data:\n",
    "            if d['pred'][0:3] == 'yes':\n",
    "                if d['label'] == 1:\n",
    "                    true_pos.append(d)\n",
    "                    correct += 1\n",
    "                    pos += 1\n",
    "                else:\n",
    "                    false_pos.append(d)\n",
    "                    neg += 1\n",
    "            else:\n",
    "                if d['label'] == 0:\n",
    "                    true_neg.append(d)\n",
    "                    correct += 1\n",
    "                    neg += 1\n",
    "                else:\n",
    "                    false_neg.append(d)\n",
    "                    pos += 1\n",
    "\n",
    "        true_pos_all[name], true_neg_all[name], false_pos_all[name], false_neg_all[name] = true_pos, true_neg, false_pos, false_neg\n",
    "        accuracy[name], precision[name], recall[name] = correct/len(data), len(true_pos) / (len(true_pos) + len(false_pos)), len(true_pos) / (len(true_pos) + len(false_neg))\n",
    "        f1[name] =  2 * len(true_pos) / (2 * len(true_pos) + len(false_pos) + len(false_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>With Learning</th>\n",
       "      <td>78.9</td>\n",
       "      <td>73.5</td>\n",
       "      <td>76.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Precision  Recall    F1\n",
       "With Learning       78.9    73.5  76.1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Precision'] = pd.Series(precision)\n",
    "df['Recall'] = pd.Series(recall)\n",
    "df['F1'] = pd.Series(f1)\n",
    "df['Precision'] *= 100\n",
    "df['Recall'] *= 100\n",
    "df['F1'] *= 100\n",
    "df.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '???'\n",
    "\n",
    "with open(f'./{folder}/true_pos.json', 'w') as f:\n",
    "        json.dump(true_pos_all, f, indent=4)\n",
    "with open(f'./{folder}/true_neg.json', 'w') as f:\n",
    "        json.dump(true_neg_all, f, indent=4)\n",
    "with open(f'./{folder}/false_pos.json', 'w') as f:\n",
    "        json.dump(false_pos_all, f, indent=4)\n",
    "with open(f'./{folder}/false_neg.json', 'w') as f:\n",
    "        json.dump(false_neg_all, f, indent=4)\n",
    "# with open(f'./{folder}/accuracy.json', 'w') as f:\n",
    "#         json.dump(accuracy, f, indent=4)\n",
    "with open(f'./{folder}/f1.json', 'w') as f:\n",
    "        json.dump(f1, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacegpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
